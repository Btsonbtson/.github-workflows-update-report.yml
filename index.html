# ======= SMART DEPENDENCY CHECK =======
required_modules = [
    ('feedparser', 'feedparser'),
    ('requests', 'requests'),
    ('bs4', 'beautifulsoup4'),
    ('dateutil', 'python-dateutil')
]
missing_modules = []

for module_name, install_name in required_modules:
    try:
        __import__(module_name)
    except ImportError:
        missing_modules.append((module_name, install_name))

if missing_modules:
    print("â— Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ ÎµÎ»Î»ÎµÎ¯Ï€Î¿Î½Ï„Î± modules:")
    for module, install in missing_modules:
        print(f"- {module} (Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·: pip install {install})")
    print("\nâš ï¸ Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ³ÎºÎ±Ï„Î­ÏƒÏ„Î·ÏƒÎµ Ï„Î± Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ ÎºÎ±Î¹ Î¾Î±Î½Î±Ï„ÏÎ­Î¾Îµ Ï„Î¿ script.")
    exit(1)

# ======= END SMART CHECK =======

import feedparser
import datetime
import os
import requests
from bs4 import BeautifulSoup
from dateutil import parser as date_parser

# Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚
WHATSAPP_PHONE = '+306932377969'
CALLMEBOT_API_KEY = '7338852'
NEWS_DIR = 'C:/Users/boikos.y.CALLCENTER/Morning Brief/'

# Geopolitics Image (Ï„Î¿Ï€Î¹ÎºÏŒ Î±ÏÏ‡ÎµÎ¯Î¿)
GEOPOLITICS_IMAGE = 'geopolitics_image.png'

# Section YouTube Î¼Îµ Î±Ï€Î»Î¬ hyperlinks
def fetch_youtube_links_sections():
    section = "<h2>ğŸ“º YouTube Latest Videos</h2><ul>"
    section += "<li><a href='https://www.youtube.com/@LAMBROSKALARRYTIS/videos' target='_blank'>Lambros Kalarritis</a></li>"
    section += "<li><a href='https://www.youtube.com/@geostratigiki/videos' target='_blank'>Geostratigiki</a></li>"
    section += "<li><a href='https://www.youtube.com/@Enimerosi.kai.Skepsi/videos' target='_blank'>Enimerosi kai Skepsi</a></li>"
    section += "</ul>"
    return section

def fetch_sports_youtube_links():
    section = "<h2>âš½ Sports YouTube Channels</h2><ul>"
    section += "<li><a href='https://www.youtube.com/@sporfm946/videos' target='_blank'>SporFM 94.6</a></li>"
    section += "<li><a href='https://www.youtube.com/@REDSPORTS7/videos' target='_blank'>RedSports 7</a></li>"
    section += "</ul>"
    return section

# Bankingnews Section (Î¼ÏŒÎ½Î¿ hyperlink + ÎµÎ¹ÎºÏŒÎ½Î±)
def fetch_bankingnews_section():
    return """
    <h2>ğŸ“° Top Market Summary</h2>
    <img src='https://www.bankingnews.gr/templates/banking/images/logo.png' alt='Bankingnews'>
    <p><a href='https://www.bankingnews.gr' target='_blank'>Î”ÎµÎ¯Ï„Îµ Ï„Î± Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ´Ï</a></p>
    """

# Shipping Indexes Section (Î¼ÏŒÎ½Î¿ hyperlink + ÎµÎ¹ÎºÏŒÎ½Î±)
def fetch_shipping_indexes_section():
    return """
    <h2>ğŸš¢ Shipping Indexes Daily Values</h2>
    <img src='https://seecapitalmarkets.com/wp-content/uploads/2023/02/logo-see-capital-markets.png' alt='Shipping Indexes'>
    <p><a href='https://www.seecapitalmarkets.com/ShippingIndexes' target='_blank'>Î”ÎµÎ¯Ï„Îµ Ï„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ± Shipping Indexes ÎµÎ´Ï</a></p>
    """

# FX Section Î¼Îµ 2 hyperlinks + ÎµÎ¹ÎºÏŒÎ½Î±
def fetch_fx_section():
    return """
    <h2>ğŸ’± FX & Commodities</h2>
    <img src='https://seecapitalmarkets.com/wp-content/uploads/2023/02/logo-see-capital-markets.png' alt='Forex'>
    <ul>
        <li><a href='https://www.seecapitalmarkets.com/Forex' target='_blank'>Forex Markets</a></li>
        <li><a href='https://www.seecapitalmarkets.com/Commodities' target='_blank'>Commodities Markets</a></li>
    </ul>
    """
# RSS ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚ ÎºÎ±Î¹ feeds
KEYWORDS = {
    'Geopolitics': ['Î•Î»Î»Î·Î½Î¿Ï„Î¿Ï…ÏÎº', 'Geopolitics', 'Geo-politics', 'Î´Î¹ÎµÎ¸Î½ÎµÎ¯Ï‚ ÏƒÏ‡Î­ÏƒÎµÎ¹Ï‚', 'Foreign Affairs', 'ÎÎ‘Î¤ÎŸ', 'War'],
    'Markets': ['S&P500', 'Dow Jones', 'NASDAQ', 'FTSE', 'ASE', 'Î§ÏÎ·Î¼Î±Ï„Î¹ÏƒÏ„Î®ÏÎ¹Î¿'],
    'Energy': ['Brent', 'Crude Oil', 'Energy', 'BIFFEX', 'Shipping Index', 'Baltic'],
    'Sports': ['ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚', 'Olympiakos', 'Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿']
}

FEEDS = [
    'https://www.politico.eu/feed/',
    'https://www.reuters.com/tools/rss',
    'https://www.thestreet.com/feeds/rss/articles',
    'https://www.lemonde.fr/en/rss/une.xml',
    'https://www.economist.com/rss',
    'https://www.rednews.gr/feed/',
    'https://www.foreignaffairs.com/rss.xml',
    'https://www.defence-point.gr/news/',
    'https://flight.com.gr/',
    'https://elisme.gr/',
    'https://nordicmonitor.com/'
]

def is_recent(entry):
    try:
        published = date_parser.parse(entry.get('published', ''))
        return (datetime.datetime.now(datetime.timezone.utc) - published).total_seconds() <= 86400
    except:
        return False

def fetch_news():
    categorized_news = {key: [] for key in KEYWORDS.keys()}
    for url in FEEDS:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                if not is_recent(entry):
                    continue
                for category, words in KEYWORDS.items():
                    if any(word.lower() in (entry.title + entry.get('description', '')).lower() for word in words):
                        image_url = ''
                        if 'media_content' in entry:
                            image_url = entry.media_content[0]['url']
                        elif 'enclosure' in entry and 'url' in entry.enclosure:
                            image_url = entry.enclosure['url']
                        categorized_news[category].append({
                            'title': entry.title,
                            'link': entry.link,
                            'published': entry.get('published', ''),
                            'image': image_url
                        })
        except Exception as e:
            print(f"Î£Ï†Î¬Î»Î¼Î± feed {url}: {e}")
    return categorized_news

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„ÎµÎ»Î¹ÎºÎ¿Ï report
today = datetime.datetime.now().strftime('%Y-%m-%d')
html_file = f'{NEWS_DIR}daily_news_{today}.html'
news_data = fetch_news()

html_content = f"""
<!DOCTYPE html>
<html lang="el">
<head>
    <meta charset="UTF-8">
    <title>Î—Î¼ÎµÏÎ®ÏƒÎ¹Î¿ Î”ÎµÎ»Ï„Î¯Î¿ - {today}</title>
    <style>
        body {{ font-family: Georgia, 'Times New Roman', Times, serif; background: #f1f1f1; color: #333; margin: 0; padding: 0; }}
        .container {{ max-width: 1200px; margin: auto; background: #fff; padding: 20px; box-shadow: 0 0 15px rgba(0,0,0,0.1); }}
        header {{ text-align: center; border-bottom: 4px solid #222; margin-bottom: 20px; }}
        header h1 {{ margin: 0; font-size: 2.5em; }}
        .section {{ margin-bottom: 40px; }}
        h2 {{ border-bottom: 2px solid #999; padding-bottom: 5px; }}
        .news-grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 15px; }}
        .news-item img {{ max-width: 100%; height: auto; border-radius: 5px; }}
        footer {{ text-align: center; font-size: 0.8em; color: #888; margin-top: 40px; }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Î—Î¼ÎµÏÎ®ÏƒÎ¹Î¿ Î”ÎµÎ»Ï„Î¯Î¿ - {today}</h1>
        </header>
"""

html_content += fetch_bankingnews_section()
html_content += fetch_shipping_indexes_section()
html_content += fetch_fx_section()
html_content += fetch_youtube_links_sections()

# ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± Î¬ÏÎ¸ÏÎ±
for category, articles in news_data.items():
    if articles:
        html_content += f"<h2>{category}</h2>"
        if category == 'Geopolitics':
            html_content += f"<img src='{GEOPOLITICS_IMAGE}' alt='Geopolitics Image'>"
        if category == 'Sports':
            html_content += fetch_sports_youtube_links()
        html_content += "<div class='news-grid'>"
        for art in articles:
            img_tag = f"<img src='{art['image']}' alt=''>" if art['image'] else ''
            html_content += f"""
            <div class='news-item'>
                {img_tag}
                <h3><a href="{art['link']}" target="_blank">{art['title']}</a></h3>
                <small>{art['published']}</small>
            </div>
            """
        html_content += "</div>"

html_content += """
    <footer>Î‘Î½Î±Ï†Î¿ÏÎ¬ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± (V3 PRO).</footer>
    </div>
</body>
</html>
"""

with open(html_file, 'w', encoding='utf-8') as f:
    f.write(html_content)
